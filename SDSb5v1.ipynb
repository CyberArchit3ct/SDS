{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0255c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ✅ Ultra-Accurate EfficientNet-B5 Snake Classifier for Google Colab\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.amp import GradScaler, autocast\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67022d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfc6d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Transforms & Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((456, 456)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((456, 456)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_path = '/content/Snake_Dataset'\n",
    "split_path = '/content/Split_Snake_Dataset'\n",
    "\n",
    "assert os.path.exists(data_path), f\"Dataset not found at {data_path}\"\n",
    "\n",
    "# Auto Split if not already split\n",
    "if not os.path.exists(split_path):\n",
    "    print(\"🛠️ Splitting dataset...\")\n",
    "    os.makedirs(os.path.join(split_path, 'train'))\n",
    "    os.makedirs(os.path.join(split_path, 'val'))\n",
    "\n",
    "    full_dataset = ImageFolder(data_path)\n",
    "    num_classes = len(full_dataset.classes)\n",
    "    class_names = full_dataset.classes\n",
    "\n",
    "    class_indices = {cls: [] for cls in class_names}\n",
    "    for idx, (img_path, label) in enumerate(full_dataset.samples):\n",
    "        cls = class_names[label]\n",
    "        class_indices[cls].append(img_path)\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_dir_train = os.path.join(split_path, 'train', cls)\n",
    "        cls_dir_val = os.path.join(split_path, 'val', cls)\n",
    "        os.makedirs(cls_dir_train, exist_ok=True)\n",
    "        os.makedirs(cls_dir_val, exist_ok=True)\n",
    "\n",
    "        imgs = class_indices[cls]\n",
    "        split_idx = int(len(imgs) * 0.85)\n",
    "        for img in imgs[:split_idx]:\n",
    "            shutil.copy(img, os.path.join(cls_dir_train, os.path.basename(img)))\n",
    "        for img in imgs[split_idx:]:\n",
    "            shutil.copy(img, os.path.join(cls_dir_val, os.path.basename(img)))\n",
    "else:\n",
    "    print(\"📁 Dataset already split.\")\n",
    "\n",
    "train_dataset = ImageFolder(os.path.join(split_path, 'train'), transform=transform)\n",
    "val_dataset = ImageFolder(os.path.join(split_path, 'val'), transform=transform)\n",
    "num_classes = len(train_dataset.classes)\n",
    "dataset_classes = train_dataset.classes\n",
    "\n",
    "print(f\"🪲 Classes: {num_classes} => {dataset_classes}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6f0f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Model\n",
    "model = timm.create_model('tf_efficientnet_b5_ns', pretrained=True, drop_rate=0.4, drop_path_rate=0.4)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.BatchNorm1d(model.num_features),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(model.num_features, num_classes)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8513de2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. Loss, Optimizer, Scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb6024",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Train & Validate\n",
    "num_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "\n",
    "    for images, labels in train_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(dtype=torch.float16):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        train_bar.set_postfix(loss=running_loss/(total//8), acc=100.*correct/total)\n",
    "\n",
    "    train_acc = 100.*correct/total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast(dtype=torch.float16):\n",
    "                outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100.*val_correct/val_total\n",
    "    scheduler.step(epoch + val_acc)\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_b5_model.pth\")\n",
    "        print(\"✅ Saved Best Model\")\n",
    "\n",
    "print(f\"\\n📊 Final Evaluation Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset_classes))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=dataset_classes, yticklabels=dataset_classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c530d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 6. Inference on User Image\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "model.eval()\n",
    "for fname in uploaded.keys():\n",
    "    img = Image.open(fname).convert('RGB')\n",
    "    img_tensor = inference_transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        with autocast(dtype=torch.float16):\n",
    "            pred = model(img_tensor)\n",
    "            probs = torch.softmax(pred, dim=1)\n",
    "            top3_probs, top3_indices = torch.topk(probs, 3)\n",
    "\n",
    "    print(f\"\\n🧠 Prediction for '{fname}':\")\n",
    "    for i in range(3):\n",
    "        print(f\"{dataset_classes[top3_indices[0][i]]}: {top3_probs[0][i].item()*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
