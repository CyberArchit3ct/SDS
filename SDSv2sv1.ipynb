{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3fbf5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Ultra-Accurate EfficientNet-V2-S Snake Classifier for VS Code/Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2631f",
   "metadata": {},
   "source": [
    "<!-- **Instructions:**\n",
    "1. Install required packages: `pip install timm torch torchvision scikit-learn seaborn tqdm`\n",
    "2. Place your dataset in `./Snake_Dataset/<class_name>/*.jpg`.\n",
    "3. Run this notebook in VS Code or Jupyter.\n",
    "4. After training, upload an image for inference when prompted. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddae15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tkinter import Tk, filedialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4746012",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8260ef7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Paths and Constants\n",
    "data_dir = './Snake_Dataset'\n",
    "split_dir = './Split_Snake_Dataset'\n",
    "train_ratio = 0.85\n",
    "img_size = 384\n",
    "batch_size = 8\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f975b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4ee6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. Split Dataset if Needed\n",
    "if not os.path.exists(split_dir):\n",
    "    print('Splitting dataset...')\n",
    "    os.makedirs(os.path.join(split_dir, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_dir, 'val'), exist_ok=True)\n",
    "    full = ImageFolder(data_dir)\n",
    "    classes = full.classes\n",
    "    samples = full.samples\n",
    "    # Map class to image paths\n",
    "    cls_to_paths = {cls: [] for cls in classes}\n",
    "    for path, label in samples:\n",
    "        cls_to_paths[classes[label]].append(path)\n",
    "    # Copy files\n",
    "    for cls, paths in cls_to_paths.items():\n",
    "        train_count = int(len(paths)*train_ratio)\n",
    "        for i, p in enumerate(paths):\n",
    "            dest = 'train' if i<train_count else 'val'\n",
    "            out_dir = os.path.join(split_dir, dest, cls)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            shutil.copy(p, out_dir)\n",
    "else:\n",
    "    print('Dataset already split.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d7ea3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Load Datasets & Dataloaders\n",
    "train_ds = ImageFolder(os.path.join(split_dir,'train'), transform=train_transform)\n",
    "val_ds = ImageFolder(os.path.join(split_dir,'val'), transform=train_transform)\n",
    "classes = train_ds.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(f'Classes ({num_classes}):', classes)\n",
    "\n",
    "dl_train = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "dl_val   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15d6da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 6. Create Model\n",
    "model = timm.create_model('tf_efficientnetv2_s_in21k', pretrained=True, num_classes=num_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dabbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 7. Loss, Optimizer, Scheduler, AMP\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78020d0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 8. Training Loop\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0,0,0\n",
    "    for imgs, labels in tqdm(dl_train, desc=f'Epoch {epoch+1}/{num_epochs}'):  \n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outs = model(imgs)\n",
    "            loss = criterion(outs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        preds = outs.argmax(dim=1)\n",
    "        correct += (preds==labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_acc = correct/total*100\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0,0\n",
    "    all_preds, all_labels = [],[]\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dl_val:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            with autocast(): outs = model(imgs)\n",
    "            preds = outs.argmax(dim=1)\n",
    "            all_preds += preds.cpu().tolist()\n",
    "            all_labels += labels.cpu().tolist()\n",
    "            correct += (preds==labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct/total*100\n",
    "    scheduler.step(epoch + val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Train Loss {total_loss/len(dl_train):.4f}, Train Acc {train_acc:.2f}%, Val Acc {val_acc:.2f}%')\n",
    "    if val_acc>best_acc:\n",
    "        best_acc=val_acc\n",
    "        torch.save(model.state_dict(),'best_efficientv2s.pth')\n",
    "        print('Saved Best Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353d540",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 9. Final Evaluation\n",
    "print('\\nFinal Evaluation')\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f3c85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 10. Inference: Load Model & Predict\n",
    "# File dialog\n",
    "Tk().withdraw()\n",
    "img_path = filedialog.askopenfilename(title='Select Snake Image')\n",
    "if img_path:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    tensor = inference_transform(img).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad(), autocast():\n",
    "        out = model(tensor)\n",
    "        probs = torch.softmax(out, dim=1)\n",
    "        top3 = probs.topk(3)\n",
    "    print('Top-3 Predictions:')\n",
    "    for prob, idx in zip(top3.values[0], top3.indices[0]):\n",
    "        print(f\"{classes[idx]}: {prob.item()*100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
